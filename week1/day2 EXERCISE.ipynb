{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "# list of dictionaries\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality, engaging content such as articles, blog posts, social media posts, and even entire books. This can help businesses save time and resources on content creation.\n",
      "2. **Product Design**: Generative AI can assist in the design of products, including 3D models, logos, and packaging. This can help companies reduce costs associated with manual design and development.\n",
      "3. **Marketing Automation**: Generative AI can be used to generate personalized marketing messages, offers, and campaigns tailored to individual customers' preferences and behaviors.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI-powered chatbots and virtual assistants can provide 24/7 customer support, helping businesses improve customer experience and reduce response times.\n",
      "5. **Data Analysis and Visualization**: Generative AI can help analyze large datasets, identify patterns, and visualize insights in a more intuitive way, enabling data-driven decision-making.\n",
      "6. **Music Composition and Audio Processing**: Generative AI can be used to create original music tracks, generate audio effects, and even edit existing audio content, such as videos or podcasts.\n",
      "7. **Image and Video Generation**: Generative AI can generate high-quality images and videos for advertising, marketing, and entertainment purposes, such as creating realistic product demos or cinematic sequences.\n",
      "8. **Language Translation**: Generative AI-powered translation tools can help businesses communicate with global customers more effectively, reducing language barriers and improving customer engagement.\n",
      "9. **Predictive Analytics**: Generative AI can be used to build predictive models that forecast customer behavior, sales trends, and market demand, enabling businesses to make data-driven decisions.\n",
      "10. **Cybersecurity**: Generative AI-powered security tools can help detect and respond to cyber threats more effectively, reducing the risk of data breaches and protecting business assets.\n",
      "\n",
      "Some specific industries where generative AI has a significant impact include:\n",
      "\n",
      "1. **Advertising and Marketing**: Generative AI can help create personalized ad campaigns, generate high-quality content, and automate marketing tasks.\n",
      "2. **Finance and Banking**: Generative AI can be used to analyze large datasets, predict market trends, and identify potential investment opportunities.\n",
      "3. **Healthcare**: Generative AI can assist in medical research, develop personalized treatment plans, and analyze medical data to improve patient outcomes.\n",
      "4. **Education**: Generative AI can help create customized learning materials, grade assignments, and provide real-time feedback to students.\n",
      "5. **Retail**: Generative AI can be used to generate product recommendations, optimize supply chain operations, and personalize customer experiences.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4942e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting claude\n",
      "  Downloading claude-0.4.10.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m401.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp~=3.5 (from claude)\n",
      "  Using cached aiohttp-3.11.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting Jinja2~=2.10 (from claude)\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting configpp~=0.3 (from claude)\n",
      "  Downloading configpp-0.5.0.tar.gz (354 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lxml~=4.4 (from claude)\n",
      "  Downloading lxml-4.9.4-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting pymemcache~=2.2 (from claude)\n",
      "  Downloading pymemcache-2.2.2-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cssselect~=1.1 (from claude)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools~=3.1 (from claude)\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pychromecast~=3.2 (from claude)\n",
      "  Downloading PyChromecast-3.2.3-py2.py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting aiohttp-middlewares~=1.1 (from claude)\n",
      "  Downloading aiohttp_middlewares-1.2.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp~=3.5->claude)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp~=3.5->claude)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp~=3.5->claude) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.5->claude)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.5->claude)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp~=3.5->claude)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp~=3.5->claude)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting async-timeout<5.0,>=3.0 (from aiohttp-middlewares~=1.1->claude)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting voluptuous~=0.11 (from configpp~=0.3->claude)\n",
      "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting command-tree~=0.7 (from configpp~=0.3->claude)\n",
      "  Downloading command-tree-0.7.1.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-slugify~=1.2 (from configpp~=0.3->claude)\n",
      "  Downloading python-slugify-1.2.6.tar.gz (6.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil~=2.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from configpp~=0.3->claude) (2.9.0.post0)\n",
      "Collecting ruamel.yaml~=0.15.44 (from configpp~=0.3->claude)\n",
      "  Downloading ruamel.yaml-0.15.100.tar.gz (318 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-inspect~=0.3 (from configpp~=0.3->claude)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting PyYAML~=5.1 (from configpp~=0.3->claude)\n",
      "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[54 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing lib3/PyYAML.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to lib3/PyYAML.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to lib3/PyYAML.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 304, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 320, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 271, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/__init__.py\", line 117, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 186, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/core.py\", line 202, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 983, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/dist.py\", line 999, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/dist.py\", line 1002, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/command/egg_info.py\", line 312, in run\n",
      "  \u001b[31m   \u001b[0m     self.find_sources()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/command/egg_info.py\", line 320, in find_sources\n",
      "  \u001b[31m   \u001b[0m     mm.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/command/egg_info.py\", line 543, in run\n",
      "  \u001b[31m   \u001b[0m     self.add_defaults()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/command/egg_info.py\", line 581, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/command/sdist.py\", line 109, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     super().add_defaults()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/command/sdist.py\", line 239, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/command/sdist.py\", line 324, in _add_defaults_ext\n",
      "  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n",
      "  \u001b[31m   \u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 201, in get_source_files\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/76/5_sx12y16fzfchs7_d4mwh_c0000gn/T/pip-build-env-r9vwvfdg/overlay/lib/python3.11/site-packages/setuptools/_distutils/cmd.py\", line 120, in __getattr__\n",
      "  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n",
      "  \u001b[31m   \u001b[0m AttributeError: cython_sources\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f48d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from ollama) (2.10.5)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Downloading ollama-0.4.6-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: httpx, ollama\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "Successfully installed httpx-0.27.2 ollama-0.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have feelings or emotions like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ccc691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 2 + 4 is 6.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, what is 2+4\"},\n",
    "]\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat(messages=messages, model=MODEL)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a06e88e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# now I want to add a system message to the conversation\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, what is 2+4\"},\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assitant\"}\n",
    "]\n",
    "\n",
    "response = ollama.chat(messages=messages, model=MODEL)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources while creating engaging content for their audience.\n",
      "2. **Product Design and Creation**: Generative AI can be used to design and create new product prototypes, reducing the need for manual sketching and prototyping.\n",
      "3. **Personalized Recommendations**: AI can personalize product recommendations based on user behavior, preferences, and purchase history, increasing customer engagement and sales.\n",
      "4. **Influencer Identification**: Generative AI can help identify social media influencers who align with a brand's values and target audience, streamlining the influencer marketing process.\n",
      "5. **Chatbots and Virtual Assistants**: AI-powered chatbots can provide 24/7 customer support, helping to minimize response times and improve overall customer satisfaction.\n",
      "6. **Image Editing and Enhancement**: Generative AI can be used to edit and enhance images, making them more visually appealing for marketing campaigns, product photography, and social media content.\n",
      "7. **Video Generation**: AI can generate high-quality video content, such as Explainer videos, promotional videos, and more, reducing production costs and time.\n",
      "8. **Music and Sound Effects Generation**: Generative AI can create custom music tracks and sound effects that enhance the overall brand experience in advertising, animation, and gaming industries.\n",
      "9. **Text Summarization**: AI can summarize long documents and articles into concise summaries, saving businesses time and resources while distilling complex information.\n",
      "10. **Data Analysis and Insights**: Generative AI can analyze large datasets to identify patterns, trends, and insights, helping businesses make data-driven decisions.\n",
      "11. **Automated Reporting**: AI-powered tools can generate reports automatically, streamlining workflows and reducing the need for manual reporting.\n",
      "12. **Marketing Campaign Optimization**: Generative AI can optimize marketing campaigns by predicting customer behavior, identifying product opportunities, and improving return on investment (ROI).\n",
      "13. **Speech-to-Text Transcription**: AI-powered transcription tools can automate speech-to-text translation, freeing up staff time and increasing productivity.\n",
      "14. **Creative Writing Assistance**: Generative AI can assist writers with research assistance, fact-checking, and generating ideas for creative projects.\n",
      "15. **Data Cleanup and Scraping**: Generative AI-powered tools can automatically clean and scrape data from various sources, making it easier to integrate and analyze.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI, which is expected to continue evolving and expanding in the coming years.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44fa2065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 2 + 4 is 6.\n"
     ]
    }
   ],
   "source": [
    "# now I want to add a system message to the conversation\n",
    "\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, what is 2+4\"}]\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d5686-4e76-4110-b65a-b3906c35c0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Het lijkt erop dat je kiest voor Crossroads om een huurwoning te zoeken. Hier zijn de belangrijkste details over de huurwoningen die ik kon vinden:\n",
       "\n",
       "1. **Radarweg 297A**: Typ TR-U2, huurprijs € 1049,- per maand, woonoppervlakte 68,2 m²\n",
       "2. **Radarweg 297B**: Typ TR-V2, huurprijs € 1189,- per maand, woonoppervlakte 65,2 m²\n",
       "3. **Radarweg 297C**: Typ TR-U1, huurprijs € 1249,- per maand, woonoppervlakte 68,2 m² (niet meer beschikbaar)\n",
       "4. **Radarweg 297D**: Typ TR-V1, huurprijs € 1299,- per maand, woonoppervlakte 65,2 m² (niet meer beschikbaar)\n",
       "\n",
       "De huurwoningen hebben allemaal een loggia met vlonderdelen en verschillende kamers. De prijzen variëren van € 1049,- per maand tot € 1299,- per maand.\n",
       "\n",
       "Ik hoop dat deze informatie helpen bij het zoeken naar de juiste huurwoning in Crossroads!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a table of houses of this website in markdown. \\\n",
    "Include the price of the house, the status, \\\n",
    "and the living area \\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(model=MODEL, messages=messages_for(website))\n",
    "    # response = openai.chat.completions.create(\n",
    "    #     model = \"gpt-4o-mini\",\n",
    "    #     messages = messages_for(website)\n",
    "    # )\n",
    "    return response['message']['content']\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "web = Website(\"https://edwarddonner.com\")\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a table with key features of the every unique house, \\\n",
    "in a markdown file\"\n",
    "# user_prompt = user_prompt_for(web)\n",
    "\n",
    "display_summary(\"https://crossroadsamsterdam.nl/woningaanbod/verdieping-26/\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
